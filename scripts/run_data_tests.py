#!/usr/bin/env python3
"""
æ•°æ®å±‚æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•è¿è¡Œè„šæœ¬
"""
import sys
import os
import subprocess
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def run_tests(test_type="all", parallel=True, coverage=True):
    """
    è¿è¡Œæ•°æ®å±‚æµ‹è¯•
    
    Args:
        test_type: æµ‹è¯•ç±»å‹ ("unit", "integration", "all")
        parallel: æ˜¯å¦å¹¶è¡Œè¿è¡Œ
        coverage: æ˜¯å¦ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
    """
    print("=" * 60)
    print("å¼€å§‹è¿è¡Œæ•°æ®å±‚æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # è®¾ç½®æµ‹è¯•å‚æ•°
    pytest_args = ["-v", "--tb=short"]
    
    if parallel:
        pytest_args.extend(["-n", "auto"])
    
    if coverage:
        pytest_args.extend([
            "--cov=src/data",
            "--cov=src/infrastructure",
            "--cov-report=html:htmlcov/data_coverage",
            "--cov-report=term-missing"
        ])
    
    # æ ¹æ®æµ‹è¯•ç±»å‹é€‰æ‹©æµ‹è¯•æ–‡ä»¶
    if test_type == "unit":
        test_paths = [
            "tests/unit/data/test_data_manager.py",
            "tests/unit/data/test_base_loader.py", 
            "tests/unit/data/test_validator.py"
        ]
    elif test_type == "integration":
        test_paths = [
            "tests/integration/test_data_infrastructure_integration.py"
        ]
    else:  # all
        test_paths = [
            "tests/unit/data/",
            "tests/integration/test_data_infrastructure_integration.py"
        ]
    
    # è¿è¡Œæµ‹è¯•
    start_time = time.time()
    
    for test_path in test_paths:
        print(f"\nè¿è¡Œæµ‹è¯•: {test_path}")
        print("-" * 40)
        
        cmd = ["python", "-m", "pytest"] + pytest_args + [test_path]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # è¾“å‡ºæµ‹è¯•ç»“æœ
            if result.stdout:
                print(result.stdout)
            if result.stderr:
                print("é”™è¯¯è¾“å‡º:")
                print(result.stderr)
            
            if result.returncode == 0:
                print(f"âœ… {test_path} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_path} æµ‹è¯•å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿è¡Œæµ‹è¯•æ—¶å‡ºé”™: {e}")
            return False
    
    end_time = time.time()
    duration = end_time - start_time
    
    print("\n" + "=" * 60)
    print(f"æµ‹è¯•å®Œæˆ! æ€»è€—æ—¶: {duration:.2f}ç§’")
    print("=" * 60)
    
    return True

def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("è¿è¡Œæ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    pytest_args = [
        "-v",
        "--tb=short",
        "-m", "performance",
        "tests/unit/data/test_data_manager.py",
        "tests/unit/data/test_base_loader.py"
    ]
    
    cmd = ["python", "-m", "pytest"] + pytest_args
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.stdout:
            print(result.stdout)
        if result.stderr:
            print("é”™è¯¯è¾“å‡º:")
            print(result.stderr)
        
        if result.returncode == 0:
            print("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ è¿è¡Œæ€§èƒ½æµ‹è¯•æ—¶å‡ºé”™: {e}")
        return False
    
    return True

def run_error_handling_tests():
    """è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•")
    print("=" * 60)
    
    pytest_args = [
        "-v",
        "--tb=short",
        "-m", "error_handling",
        "tests/unit/data/test_data_manager.py",
        "tests/unit/data/test_base_loader.py",
        "tests/unit/data/test_validator.py"
    ]
    
    cmd = ["python", "-m", "pytest"] + pytest_args
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.stdout:
            print(result.stdout)
        if result.stderr:
            print("é”™è¯¯è¾“å‡º:")
            print(result.stderr)
        
        if result.returncode == 0:
            print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•æ—¶å‡ºé”™: {e}")
        return False
    
    return True

def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = Path("test_reports")
    report_dir.mkdir(exist_ok=True)
    
    # ç”ŸæˆHTMLæŠ¥å‘Š
    cmd = [
        "python", "-m", "pytest",
        "--html=test_reports/data_test_report.html",
        "--self-contained-html",
        "tests/unit/data/",
        "tests/integration/test_data_infrastructure_integration.py"
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… æµ‹è¯•æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
            print(f"æŠ¥å‘Šä½ç½®: {report_dir.absolute()}")
        else:
            print("âŒ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            if result.stderr:
                print(result.stderr)
            return False
            
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•°æ®å±‚æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument(
        "--test-type", 
        choices=["unit", "integration", "all"], 
        default="all",
        help="æµ‹è¯•ç±»å‹"
    )
    parser.add_argument(
        "--no-parallel", 
        action="store_true",
        help="ç¦ç”¨å¹¶è¡Œæµ‹è¯•"
    )
    parser.add_argument(
        "--no-coverage", 
        action="store_true",
        help="ç¦ç”¨è¦†ç›–ç‡æŠ¥å‘Š"
    )
    parser.add_argument(
        "--performance-only", 
        action="store_true",
        help="ä»…è¿è¡Œæ€§èƒ½æµ‹è¯•"
    )
    parser.add_argument(
        "--error-handling-only", 
        action="store_true",
        help="ä»…è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•"
    )
    parser.add_argument(
        "--generate-report", 
        action="store_true",
        help="ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­
    try:
        import pandas as pd
        import pytest
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿åœ¨conda rqaç¯å¢ƒä¸­è¿è¡Œ")
        return False
    
    # æ ¹æ®å‚æ•°è¿è¡Œç›¸åº”çš„æµ‹è¯•
    if args.performance_only:
        success = run_performance_tests()
    elif args.error_handling_only:
        success = run_error_handling_tests()
    else:
        success = run_tests(
            test_type=args.test_type,
            parallel=not args.no_parallel,
            coverage=not args.no_coverage
        )
    
    # ç”ŸæˆæŠ¥å‘Š
    if args.generate_report and success:
        generate_test_report()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥!")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 